{"data":{"markdownRemark":{"html":"<p>Software systems evolve for various reasons. The requirements change, used platforms, libraries and frameworks change. The team creating the software can change in size, or abilities. The sum of all this can be considered as the software's <em>environment</em>. The rules by which <strong>evolution</strong> in software systems play out are different to the ones we see enacted in nature. Systems that are fairly rigid in their interactions with the environment will produce large quantities of replicas with small variations, to have those survive that are most fit in their ability to survive. Also, nature has a (huge, but finite) set of mechanisms to vary, store, retrieve and put information into practice. It can't come up with a completely novel way to express certain mechanisms within the living creatures. </p>\n<p>With software systems we often have one working system which needs to evolve. We can consider a new deployment to be the next replica which ideally is better adapted to the changed environment. It is in the interest of those growing the software that deployments are kept small, much like in nature - The environment usually changes continually and hence our deployments should follow suit. In this situation it is relatively easy to be 'always-on'.</p>\n<blockquote>\n<p><strong>Always-On</strong>: a software system that stays available to its users even during those moments were the software is being adapted to the environment.</p>\n</blockquote>\n<p>Sometimes a change in the environment can be so severe that it breaks the assumption of continuality. If the new environment ideally necessitates a change in the storage structure of the system alongside a data migration (<em>something that doesn't really happen in nature, imagine introducing a fith base to the DNA and rewriting the information with the new capability</em>), 'always-on' can be a difficult attribute to attain. How do we typically deal with such a situation?</p>\n<p><img src=\"/assets/deploy-with-downtime.png\" alt=\"Change with downtime\"></p>\n<p>We suspend the 'always-on' capability, change the data, deploy the next iteration of the software and start it again. Because the software assumes the data to be in a certain way.</p>\n<p>As users we've grown used to 'always-on'-software systems. We scoff at web applications that tell us that during the next 2 hours the system will be unavailable, myself included. But, having been in the middle of such a discontinuous change in the environment during the past week, I can testify that being 'always-on' complicates matters quite a bit. How can we make sure that the system remains usable even though we change the underlying data structures? Our strategy in this case was the following:</p>\n<p><img src=\"/assets/double-deploy-wo-downtime.png\" alt=\"Change with downtime\"></p>\n<figcaption>That's what we did in the past week.</figcaption>\n<p>We deploy a version of the software that understands <strong>both old and new</strong> structure, then perform the migration to the new structures and then, at some later stage, deploy the software version that only understands the new way of doing things.</p>\n<p>Depending on the particular change, some teams may provide a read-only copy of the old system, prepare the new one, and then switch over.</p>\n<p><img src=\"/assets/read-only-mode.png\" alt=\"Put system into readonly mode\"></p>\n<figcaption>User sees 1a, then 1b (readonly) and finally 4</figcaption>\n<p>Giving a readonly version of the system can be a good choice if the usage of the software is asymetric anyway (far more reads than writes) and if it is relatively easy to duplicate tha data store, or if your read-model is expendable:</p>\n<p><img src=\"/assets/event-store-2-read-stores.png\" alt=\"1 write, 2 read models\"></p>\n<figcaption>We can decide to create a new read store 2 parallel to the previous one and then switch to the new software that works with read store 2</figcaption>\n<p>While I've never had the honour of working on an event store-based system, it seems that a different data structure of the read-model is easily attainable by creating a new projection from the relevant data and then switch to the new software. But what if you need to do changes to the <em>write model</em>? Changing something in retrospect seems to be quite the pain in this scenario.</p>\n<p>This process wasn't easy and required numerous reviews, code tweaks and <em>almost</em>-hacks that can really hit hard your ability to produce value to the software users.</p>","fields":{"slug":"/2019/07/14/migrating-data-while-being-always-on"},"frontmatter":{"date":"July 14, 2019","path":null,"title":"Migrating data while being 'always on'","tags":["software-development"]}}},"pageContext":{"title":"Migrating data while being 'always on'","previous":{"fields":{"slug":"/2019/06/21/extracting-useful-types-from-a-mapped-action-creator","published":true},"frontmatter":{"title":"Extracting useful types from a mapped action creator","tags":["programming","typescript","react"],"date":"2019/06/21"}},"next":null}}