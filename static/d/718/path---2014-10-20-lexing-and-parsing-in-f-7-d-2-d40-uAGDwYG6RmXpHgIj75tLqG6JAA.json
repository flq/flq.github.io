{"data":{"markdownRemark":{"html":"<p>With the chance of spending some time on a software project of my choice I decided to finally do something about my ignorance on tooling for parsing a piece of text into something <em>computationally useful</em>.</p>\n<p>There is a plethora of possibilities if you want to parse text following a specific grammar, I settled down for the <a href=\"http://fsprojects.github.io/FsLexYacc/fsyacc.html\">FsLexYacc</a>-toolchain which works in the context of F#. Like F#, the tooling is strongly inspired <a href=\"http://plus.kaist.ac.kr/~shoh/ocaml/ocamllex-ocamlyacc/ocamlyacc-tutorial/ocamlyacc-tutorial.html\">by similar software on the OCaml programming language</a>. Another useful link relating to OCaml but which is nonetheless useful in the context of learning the F# tooling <a href=\"http://caml.inria.fr/pub/docs/manual-ocaml/lexyacc.html\">can be found over here</a>.</p>\n<p>My intention was to write a parser for the programming language Cobol. There is <a href=\"http://www.cs.vu.nl/grammarware/vs-cobol-ii/\">a grammar definition over here</a> - it turns out that Cobol is relatively complex in that it has a gazillion of keywords which often can be used interchangeably. It is no wonder that Dijkstra once said about Cobol</p>\n<blockquote>\n<p>The use of COBOL cripples the mind; its teaching should, therefore, be regarded as a criminal offence.</p>\n</blockquote>\n<p>In order to reduce the potential time expenditure escalation that it would take to write a fully fledged Cobol parser, I decided to just be able to parse some simple examples - Interestingly, <a href=\"https://github.com/jiuweigui/cobol\">I found some on github</a>.</p>\n<p>When it comes to how to put the tools into use, there is some explaining on the project home site as well as on the <a href=\"http://en.wikibooks.org/wiki/F_Sharp_Programming/Lexing_and_Parsing\">F# wikibook</a> on how to use the lexer/parser combination, I just point you out where I got stuck - as usual it's the implicit assumption people have when writing tutorials in that somehow you know every step when using a new tool even if only half of the steps is shown.</p>\n<h2>The project file</h2>\n<p>Your F# project should contain a file defining the lexer and one defining the parser. The process goes like</p>\n<ol>\n<li>Your lexer file defines the tokens of which your parsed language consists. Those tokens are defined in the <strong>parser file</strong>.</li>\n<li>Your parser file defines the valid combination of tokens and defines for those the <strong>F# types</strong> that will result when such a combination is encountered. Hence the parser file uses types from a <strong>third file</strong>, which many name <strong>Ast (Abstract Syntax Tree)</strong>.</li>\n</ol>\n<p>That means that in order to use the tooling, somewhere in your F# project file you should have something along the lines of this:</p>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token comment\">&lt;!-- ... --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Import</span> <span class=\"token attr-name\">Project</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>..\\packages\\FsLexYacc.6.0.3\\bin\\FsLexYacc.targets<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n<span class=\"token comment\">&lt;!-- (assuming you are using the FsLexYacc Nuget) ... --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>ItemGroup</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Compile</span> <span class=\"token attr-name\">Include</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>Ast.fs<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Compile</span> <span class=\"token attr-name\">Include</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parser.fs<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>Compile</span> <span class=\"token attr-name\">Include</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>lexer.fs<span class=\"token punctuation\">\"</span></span> <span class=\"token punctuation\">/></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>FsLex</span> <span class=\"token attr-name\">Include</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>lexer.fsl<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n      <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>OtherFlags</span><span class=\"token punctuation\">></span></span>--unicode<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>OtherFlags</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>FsLex</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>FsYacc</span> <span class=\"token attr-name\">Include</span><span class=\"token attr-value\"><span class=\"token punctuation\">=</span><span class=\"token punctuation\">\"</span>parser.fsy<span class=\"token punctuation\">\"</span></span><span class=\"token punctuation\">></span></span>\n      <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>OtherFlags</span><span class=\"token punctuation\">></span></span>--module TheParser<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>OtherFlags</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>FsYacc</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>ItemGroup</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>The files <em>lexer.fs</em> and <em>parser.fs</em> are generated from the <em>lexer.fsl</em> and <em>parser.fsy</em> files, respectively. The <em>Ast.fs</em> file is made by you. The <em>FsLex</em> and <em>FsYacc</em> tasks are defined in the Import shown. </p>\n<h2>The lexer</h2>\n<p>To remind you: The lexer will tokenize your text into Tokens, which will be used by the parser to create the final Abstract Syntax Tree.</p>\n<p>{% gist flq/d17f239e6a7e122adbb0 lexer.fsl %}</p>\n<p>The somewhat difficult bit here is to figure out what went wrong when something is not working as intended. Hence, every matching bit has a logging part where one can output what is currently being matched. At this step of the process the most trouble for me was to correctly write the regular expressions, a bit like when you use sed for the first time, only different.</p>\n<h2>The parser</h2>\n<p>Once you have your tokens you need to write down the allowed combinations of those and how they translate to the types you want to end up with. The declarative nature of some functional programming constructs as well as a good understanding of recursive programming will definitely help you here.</p>\n<p>{% gist flq/d17f239e6a7e122adbb0 parser.fsy %}</p>\n<p>I didn't go as far as analyzing what went wrong when the parsing step failed, which means that you need to do some good thinking if the parsing step goes wrong - the standard error while parsing is not terribly useful, as it just states that something went wrong. Such an error usually means that some token combination was encountered that has not been catered for in the parser definition file.</p>\n<h2>The syntax tree</h2>\n<p>If all goes well, that is what you want to end up with once the parsing is complete. </p>\n<p>{% gist flq/d17f239e6a7e122adbb0 ast.fs %}</p>\n<p>Always keep in mind that in F# you only have one forward-only compiler pass, hence any types you define can only use any previously defined types. A recursive type requires the \"and\" syntax as you can see in line 46.</p>\n<h2>Conclusion</h2>\n<p>As with every new tool it needs some getting used to and especially in F#, where tools are making a transition as to how they should be obtained (modular Nuget packages instead of monolithic setups), some samples currently cannot be found. The wikibook is very helpful by defining a full example for parsing SQL. I have found a number of redundancies in my parser file, however I fear that my lack of knowledge is mostly responsible for that.</p>\n<p>Apart from that the approach scaled pretty well and I would certainly pick up a lot of speed if I were to write a full Cobol parser.</p>","frontmatter":{"date":"October 20, 2014","path":null,"title":"Lexing and parsing in F#","tags":["software-development","fsharp"]}}},"pageContext":{"title":"Lexing and parsing in F#","previous":{"fields":{"slug":"/2014/10/15/the-one-where-all-the-stuff-is-put-on-github"},"frontmatter":{"title":"The one where all the stuff is put on github","tags":["meta"],"date":"2014/10/15"}},"next":{"fields":{"slug":"/2014/11/08/getting-yesod-to-run-on-osx"},"frontmatter":{"title":"Getting Yesod to run on OSX","tags":["programming","haskell"],"date":"2014/11/08"}}}}